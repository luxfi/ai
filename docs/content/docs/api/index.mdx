---
title: API Reference
description: OpenAI-compatible API endpoints for Lux AI inference
---

# API Reference

Lux AI provides OpenAI-compatible REST APIs, allowing you to use existing SDKs and tools without modification.

## Base URL

```
https://api.lux.ai/v1
```

## Authentication

All API requests require an API key in the `Authorization` header:

```bash
curl https://api.lux.ai/v1/models \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### Getting an API Key

1. Create an account at [lux.ai](https://lux.ai)
2. Navigate to Settings > API Keys
3. Generate a new key

## Endpoints

### Models

#### List Models

```http
GET /v1/models
```

Returns available models on the network.

**Response:**
```json
{
  "object": "list",
  "data": [
    {
      "id": "llama-3.3-8b",
      "object": "model",
      "created": 1700000000,
      "owned_by": "meta"
    },
    {
      "id": "llama-3.3-70b",
      "object": "model",
      "created": 1700000000,
      "owned_by": "meta"
    }
  ]
}
```

### Chat Completions

#### Create Chat Completion

```http
POST /v1/chat/completions
```

**Request Body:**
```json
{
  "model": "llama-3.3-8b",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello, how are you?"}
  ],
  "temperature": 0.7,
  "max_tokens": 1000,
  "stream": false
}
```

**Response:**
```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1700000000,
  "model": "llama-3.3-8b",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! I'm doing well, thank you for asking."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 24,
    "completion_tokens": 12,
    "total_tokens": 36
  }
}
```

### Completions (Legacy)

#### Create Completion

```http
POST /v1/completions
```

**Request Body:**
```json
{
  "model": "llama-3.3-8b",
  "prompt": "The capital of France is",
  "max_tokens": 50,
  "temperature": 0.7
}
```

### Embeddings

#### Create Embeddings

```http
POST /v1/embeddings
```

**Request Body:**
```json
{
  "model": "text-embedding-3-small",
  "input": "The quick brown fox jumps over the lazy dog."
}
```

**Response:**
```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "index": 0,
      "embedding": [0.0023, -0.0091, ...]
    }
  ],
  "model": "text-embedding-3-small",
  "usage": {
    "prompt_tokens": 9,
    "total_tokens": 9
  }
}
```

## Parameters

### Common Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `model` | string | required | Model ID to use |
| `temperature` | float | 1.0 | Sampling temperature (0-2) |
| `max_tokens` | integer | - | Maximum tokens to generate |
| `top_p` | float | 1.0 | Nucleus sampling threshold |
| `frequency_penalty` | float | 0 | Reduce repetition (-2 to 2) |
| `presence_penalty` | float | 0 | Encourage new topics (-2 to 2) |
| `stop` | array | - | Stop sequences |
| `stream` | boolean | false | Stream responses |

### Lux AI Extensions

Additional parameters for Lux AI:

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `lux_min_trust_score` | float | 0.9 | Minimum miner trust score |
| `lux_prefer_region` | string | auto | Geographic preference |
| `lux_attestation` | boolean | true | Include attestation proof |

## Streaming

Enable streaming for real-time responses:

```bash
curl https://api.lux.ai/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-8b",
    "messages": [{"role": "user", "content": "Hello!"}],
    "stream": true
  }'
```

**Stream Response:**
```
data: {"id":"chatcmpl-abc","object":"chat.completion.chunk","created":1700000000,"model":"llama-3.3-8b","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc","object":"chat.completion.chunk","created":1700000000,"model":"llama-3.3-8b","choices":[{"index":0,"delta":{"content":"!"},"finish_reason":null}]}

data: [DONE]
```

## Error Handling

### Error Response Format

```json
{
  "error": {
    "message": "Invalid API key",
    "type": "authentication_error",
    "code": "invalid_api_key"
  }
}
```

### Error Codes

| Code | Description |
|------|-------------|
| 401 | Invalid or missing API key |
| 400 | Invalid request parameters |
| 404 | Model not found |
| 429 | Rate limit exceeded |
| 500 | Internal server error |
| 503 | No miners available |

## Rate Limits

| Tier | Requests/min | Tokens/min |
|------|-------------|------------|
| Free | 10 | 10,000 |
| Basic | 60 | 100,000 |
| Pro | 300 | 500,000 |
| Enterprise | Unlimited | Unlimited |

## SDK Examples

### Python (OpenAI SDK)

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.lux.ai/v1"
)

response = client.chat.completions.create(
    model="llama-3.3-8b",
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)

print(response.choices[0].message.content)
```

### TypeScript

```typescript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'YOUR_API_KEY',
  baseURL: 'https://api.lux.ai/v1',
});

const response = await client.chat.completions.create({
  model: 'llama-3.3-8b',
  messages: [
    { role: 'user', content: 'Hello!' }
  ],
});

console.log(response.choices[0].message.content);
```

### cURL

```bash
curl https://api.lux.ai/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-8b",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

## Next Steps

- [OpenAI Compatibility](/docs/api/openai) - Detailed compatibility guide
- [Attestation](/docs/attestation) - Verify response authenticity
- [Rewards](/docs/rewards) - Token economics
